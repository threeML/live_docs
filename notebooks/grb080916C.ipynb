{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e964bbd8",
   "metadata": {},
   "source": [
    "# Analyzing GRB 080916C\n",
    "![Alt text](https://astrobites.org/wp-content/uploads/2014/10/NASAGRBwhoa-1024x576.jpg)\n",
    "*(NASA/Swift/Cruz deWilde)*\n",
    "\n",
    "To demonstrate the capabilities and features of 3ML in, we will go through a time-integrated and time-resolved analysis. This example serves as a standard way to analyze Fermi-GBM data with 3ML as well as a template for how you can design your instrument's analysis pipeline with 3ML if you have similar data.\n",
    "\n",
    "3ML provides utilities to reduce time series data to plugins in a *correct* and *statistically justified* way (e.g., background fitting of Poisson data is done with a Poisson likelihood). The approach is generic and can be extended. For more details, see the [time series documentation](https://threeml.readthedocs.io/en/stable/notebooks/Building_Plugins_from_TimeSeries.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179b079b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb508e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "\n",
    "from threeML import *\n",
    "from threeML.io.package_data import get_path_of_data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc5ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "silence_warnings()\n",
    "%matplotlib inline\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(context=\"talk\", fscale=1, ticks=True, grid=False)\n",
    "set_threeML_style()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bccf6d",
   "metadata": {},
   "source": [
    "## Examining the catalog\n",
    "\n",
    "As with Swift and Fermi-LAT, 3ML provides a simple interface to the on-line Fermi-GBM catalog. Let's get the information for GRB 080916C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b532d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_catalog = FermiGBMBurstCatalog()\n",
    "gbm_catalog.query_sources(\"GRB080916009\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c69e49",
   "metadata": {},
   "source": [
    "To aid in quickly replicating the catalog analysis, and thanks to the tireless efforts of the Fermi-GBM team, we have added the ability to extract the analysis parameters from the catalog as well as build an **astromodels** model with the best fit parameters baked in. Using this information, one can quickly run through the catalog an replicate the entire analysis with a script. Let's give it a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476bf0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "grb_info =  gbm_catalog.get_detector_information()[\"GRB080916009\"]\n",
    "\n",
    "gbm_detectors = grb_info['detectors']\n",
    "source_interval = grb_info[\"source\"][\"fluence\"]\n",
    "background_interval = grb_info[\"background\"][\"full\"]\n",
    "best_fit_model = grb_info[\"best fit model\"][\"fluence\"]\n",
    "model =  gbm_catalog.get_model(best_fit_model, \"fluence\")[\"GRB080916009\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08a8fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fa7acd",
   "metadata": {},
   "source": [
    "## Downloading the data\n",
    "We provide a simple interface to download the Fermi-GBM data. Using the information from the catalog that we have extracted, we can download just the data from the detectors that were used for the catalog analysis. This will download the CSPEC, TTE and instrument response files from the on-line database. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdd6885",
   "metadata": {},
   "outputs": [],
   "source": [
    "dload = download_GBM_trigger_data(\"bn080916009\",detectors=gbm_detectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491b5abc",
   "metadata": {},
   "source": [
    "Let's first examine the catalog fluence fit. Using the **TimeSeriesBuilder**, we can fit the background, set the source interval, and create a 3ML plugin for the analysis. We will loop through the detectors, set their appropriate channel selections, and ensure there are enough counts in each bin to make the [PGStat profile likelihood valid](https://giacomov.github.io/Bias-in-profile-poisson-likelihood/).\n",
    "\n",
    "* First we use the CSPEC data to fit the background using the background selections. We use CSPEC because it has a longer duration for fitting the background. \n",
    "* The background is saved to an HDF5 file that stores the polynomial coefficients and selections which we can read in to the TTE file later.\n",
    "* The light curve is plotted.\n",
    "* The source selection from the catalog is set and **DispersionSpectrumLike** plugin is created.\n",
    "* The plugin has the standard GBM channel selections for spectral analysis set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e39c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluence_plugins = []\n",
    "time_series = {}\n",
    "for det in gbm_detectors:\n",
    "\n",
    "    \n",
    "    \n",
    "    ts_cspec = TimeSeriesBuilder.from_gbm_cspec_or_ctime(\n",
    "    det, cspec_or_ctime_file=dload[det][\"cspec\"], rsp_file=dload[det][\"rsp\"]\n",
    "    )\n",
    "\n",
    "    ts_cspec.set_background_interval(*background_interval.split(\",\"))\n",
    "    ts_cspec.save_background(f\"{det}_bkg.h5\", overwrite=True)\n",
    "\n",
    "    ts_tte = TimeSeriesBuilder.from_gbm_tte(\n",
    "        det,\n",
    "        tte_file=dload[det][\"tte\"],\n",
    "        rsp_file=dload[det][\"rsp\"],\n",
    "        restore_background=f\"{det}_bkg.h5\",\n",
    "    )\n",
    "    \n",
    "    time_series[det] = ts_tte\n",
    "\n",
    "    ts_tte.set_active_time_interval(source_interval)\n",
    "\n",
    "    ts_tte.view_lightcurve(-40, 100)\n",
    "    \n",
    "    fluence_plugin = ts_tte.to_spectrumlike()\n",
    "    \n",
    "    if det.startswith(\"b\"):\n",
    "        \n",
    "        fluence_plugin.set_active_measurements(\"250-30000\")\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        fluence_plugin.set_active_measurements(\"9-900\")\n",
    "    \n",
    "    fluence_plugin.rebin_on_background(1.)\n",
    "    \n",
    "    fluence_plugins.append(fluence_plugin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1961d9d",
   "metadata": {},
   "source": [
    "## Setting up the fit\n",
    "Let's see if we can reproduce the results from the catalog. \n",
    "\n",
    "### Set priors for the model\n",
    "We will fit the spectrum using Bayesian analysis, so we must set priors on the model parameters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db80b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.GRB080916009.spectrum.main.shape.alpha.prior = Truncated_gaussian(lower_bound = -1.5, upper_bound = 1, mu=-1, sigma=0.5)\n",
    "model.GRB080916009.spectrum.main.shape.beta.prior = Truncated_gaussian(lower_bound = -5, upper_bound = -1.6, mu=-2.25, sigma=0.5)\n",
    "model.GRB080916009.spectrum.main.shape.break_energy.prior = Log_normal(mu=2, sigma=1)\n",
    "model.GRB080916009.spectrum.main.shape.break_energy.bounds = (None, None)\n",
    "model.GRB080916009.spectrum.main.shape.K.prior = Log_uniform_prior(lower_bound = 1E-3, upper_bound = 1E1)\n",
    "model.GRB080916009.spectrum.main.shape.break_scale.prior = Log_uniform_prior(lower_bound = 1E-4, upper_bound = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54200bdb",
   "metadata": {},
   "source": [
    "### Clone the model and setup the Bayesian analysis class\n",
    "Next, we clone the model we built from the catalog so that we can look at the results later and fit the cloned model. We pass this model and the **DataList** of the plugins to a **BayesianAnalysis** class and set the sampler to MultiNest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4dfd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = clone_model(model)\n",
    "\n",
    "bayes = BayesianAnalysis(new_model, DataList(*fluence_plugins))\n",
    "\n",
    "# share spectrum gives a linear speed up when\n",
    "# spectrumlike plugins have the same RSP input energies\n",
    "bayes.set_sampler(\"multinest\", share_spectrum=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7532bcdb",
   "metadata": {},
   "source": [
    "### Examine at the catalog fitted model\n",
    "We can quickly examine how well the catalog fit matches the data. There appears to be a discrepancy between the data and the model! Let's refit to see if we can fix it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0249675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = display_spectrum_model_counts(bayes, min_rate=20, step=False );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e856e",
   "metadata": {},
   "source": [
    "### Run the sampler\n",
    "We let MultiNest condition the model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8297aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes.sampler.setup(n_live_points=400)\n",
    "bayes.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d96aae3",
   "metadata": {},
   "source": [
    "Now our model seems to match much better with the data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac6fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes.restore_median_fit()\n",
    "fig = display_spectrum_model_counts(bayes, min_rate=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286ae400",
   "metadata": {},
   "source": [
    "But how different are we from the catalog model? Let's plot our fit along with the catalog model. Luckily, 3ML can handle all the units for is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c05e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion = u.Unit('keV2/(cm2 s keV)').to('erg2/(cm2 s keV)')\n",
    "energy_grid = np.logspace(1,4, 100)*u.keV\n",
    "vFv = (energy_grid**2* model.get_point_source_fluxes(0, energy_grid)).to('erg2/(cm2 s keV)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a55d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_spectra(bayes.results, flux_unit='erg2/(cm2 s keV)');\n",
    "ax = fig.get_axes()[0]\n",
    "_ = ax.loglog(energy_grid, vFv, color='blue', label='catalog model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4553f174",
   "metadata": {},
   "source": [
    "## Time Resolved Analysis \n",
    "\n",
    "Now that we have examined fluence fit, we can move to performing a time-resolved analysis.\n",
    "\n",
    "### Selecting a temporal binning\n",
    "\n",
    "We first get the brightest NaI detector and create time bins via the Bayesian blocks algorithm. We can use the fitted background to make sure that our intervals are chosen in an unbiased way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40de3fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n3 = time_series['n3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3505c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "n3.create_time_bins(0,60, method=\"bayesblocks\", use_background=True, p0=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102c570f",
   "metadata": {},
   "source": [
    "Sometimes, glitches in the GBM data cause spikes in the data that the Bayesian blocks algorithm detects as fast changes in the count rate. We will have to remove those intervals manually.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note:** In the future, 3ML will provide an automated method to remove these unwanted spikes.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f548dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = n3.view_lightcurve(use_binner=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda3ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_bins = []\n",
    "for i, w in enumerate(n3.bins.widths):\n",
    "    \n",
    "    if w < 5E-2:\n",
    "        bad_bins.append(i)\n",
    "    \n",
    "    \n",
    "edges = [n3.bins.starts[0]]\n",
    "\n",
    "for i,b in enumerate(n3.bins):\n",
    "    \n",
    "    if i not in bad_bins:        \n",
    "        edges.append(b.stop)\n",
    "\n",
    "starts=edges[:-1]\n",
    "stops = edges[1:]\n",
    "\n",
    "\n",
    "n3.create_time_bins(starts, stops, method='custom')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181c0281",
   "metadata": {},
   "source": [
    "Now our light curve looks much more acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a201084",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = n3.view_lightcurve(use_binner=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e794b5e2",
   "metadata": {},
   "source": [
    "The time series objects can read time bins from each other, so we will map these time bins onto the other detectors' time series and create a list of time plugins for each detector and each time bin created above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e02ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_resolved_plugins = {}\n",
    "\n",
    "for k,v in time_series.items():\n",
    "    v.read_bins(n3)\n",
    "    time_resolved_plugins[k] = v.to_spectrumlike(from_bins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b749801d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Setting up the model\n",
    "For the time-resolved analysis, we will fit the classic *Band* function to the data. We will set some principled priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58467df",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "band = Band()\n",
    "band.alpha.prior = Truncated_gaussian(lower_bound = -1.5, upper_bound = 1, mu=-1, sigma=0.5)\n",
    "band.beta.prior = Truncated_gaussian(lower_bound = -5, upper_bound = -1.6, mu=-2, sigma=0.5)\n",
    "band.xp.prior = Log_normal(mu=2, sigma=1)\n",
    "band.xp.bounds = (0, None)\n",
    "band.K.prior = Log_uniform_prior(lower_bound=1E-10, upper_bound=1E3)\n",
    "ps = PointSource('grb', 0,0, spectral_shape=band)\n",
    "band_model = Model(ps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590639d8",
   "metadata": {},
   "source": [
    "### Perform the fits\n",
    "\n",
    "One way to perform Bayesian spectral fits to all the intervals is to loop through each one. There can are many ways to do this, so find an analysis pattern that works for you.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8992d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "results = []\n",
    "analysis = []\n",
    "for interval in range(12):\n",
    "\n",
    "    # clone the model above so that we have a separate model\n",
    "    # for each fit\n",
    "\n",
    "    this_model = clone_model(band_model)\n",
    "\n",
    "    # for each detector set up the plugin\n",
    "    # for this time interval\n",
    "\n",
    "    this_data_list = []\n",
    "    for k, v in time_resolved_plugins.items():\n",
    "\n",
    "        pi = v[interval]\n",
    "\n",
    "        if k.startswith(\"b\"):\n",
    "            pi.set_active_measurements(\"250-30000\")\n",
    "        else:\n",
    "            pi.set_active_measurements(\"9-900\")\n",
    "\n",
    "        pi.rebin_on_background(1.0)\n",
    "\n",
    "        this_data_list.append(pi)\n",
    "\n",
    "    # create a data list\n",
    "\n",
    "    dlist = DataList(*this_data_list)\n",
    "\n",
    "    # set up the sampler and fit\n",
    "\n",
    "    bayes = BayesianAnalysis(this_model, dlist)\n",
    "    \n",
    "    # get some speed with share spectrum\n",
    "    bayes.set_sampler(\"multinest\", share_spectrum=True) \n",
    "    bayes.sampler.setup(n_live_points=500)\n",
    "    bayes.sample()\n",
    "\n",
    "    # at this stage we coudl also\n",
    "    # save the analysis result to\n",
    "    # disk but we will simply hold\n",
    "    # onto them in memory\n",
    "\n",
    "    analysis.append(bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba113443",
   "metadata": {},
   "source": [
    "### Examine the fits\n",
    "Now we can look at the fits in count space to make sure they are ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ea9670",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in analysis:\n",
    "    a.restore_median_fit()\n",
    "    _ = display_spectrum_model_counts(a, min_rate=[20,20,-99], step=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acce044",
   "metadata": {},
   "source": [
    "Finally, we can plot the models together to see how the spectra evolve with time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3c0ad",
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plot_spectra(*[a.results for a in analysis[::1]], flux_unit=\"erg2/(cm2 s keV)\", fit_cmap='viridis', contour_cmap='viridis', contour_style_kwargs=dict(alpha=0.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2ef8e7",
   "metadata": {},
   "source": [
    "This example can serve as a template for performing analysis on GBM data. However, as 3ML provides an abstract interface and modular building blocks, similar analysis pipelines can be built for any time series data. "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
