{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc2b9655",
   "metadata": {},
   "source": [
    "# The 3ML workflow\n",
    "\n",
    "Generally, an analysis in 3ML is performed in 3 steps:\n",
    "\n",
    "1. Load the data: one or more datasets are loaded and then listed in a DataList object\n",
    "2. Define the model: a model for the data is defined by including one or more PointSource, ExtendedSource or ParticleSource instances\n",
    "3. Perform a likelihood or a Bayesian analysis: the data and the model are used together to perform either a Maximum Likelihood analysis, or a Bayesian analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898f3498",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "3ML is built around the concept of _plugins_. A plugin is used to load a particular type of data, or the data from a particular instrument. There is a plugin of optical data, one for X-ray data, one for Fermi/LAT data and so on. Plugins instances can be added and removed at the loading stage without changing any other stage of the analysis (but of course, you need to rerun all stages to update the results).\n",
    "\n",
    "First, let's import 3ML:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2958f9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import numpy as np\n",
    "np.seterr(all=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f604c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from threeML import *\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea609c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterthemes import jtplot\n",
    "%matplotlib inline\n",
    "jtplot.style(context=\"talk\", fscale=1, ticks=True, grid=False)\n",
    "set_threeML_style()\n",
    "silence_warnings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921d36e2",
   "metadata": {},
   "source": [
    "Let's start by loading one dataset, which in the 3ML workflow means creating an instance of the appropriate plugin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43edf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some example data\n",
    "from threeML.io.package_data import get_path_of_data_file\n",
    "\n",
    "data_path = get_path_of_data_file(\"datasets/xy_powerlaw.txt\")\n",
    "\n",
    "# Create an instance of the XYLike plugin, which allows to analyze simple x,y points\n",
    "# with error bars\n",
    "xyl = XYLike.from_text_file(\"xyl\", data_path)\n",
    "\n",
    "# Let's plot it just to see what we have loaded\n",
    "fig = xyl.plot(x_scale='log', y_scale='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa09d1a",
   "metadata": {},
   "source": [
    "Now we need to create a DataList object, which in this case contains only one instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8b4af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataList(xyl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d40343",
   "metadata": {},
   "source": [
    "The DataList object can receive one or more plugin instances on initialization. So for example, to use two datasets we can simply do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2433c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the second instance, this time of a different type\n",
    "\n",
    "pha = get_path_of_data_file(\"datasets/ogip_powerlaw.pha\")\n",
    "bak = get_path_of_data_file(\"datasets/ogip_powerlaw.bak\")\n",
    "rsp = get_path_of_data_file(\"datasets/ogip_powerlaw.rsp\")\n",
    "\n",
    "ogip = OGIPLike(\"ogip\", pha, bak, rsp)\n",
    "\n",
    "# Now use both plugins\n",
    "data = DataList(xyl, ogip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f42d7e9",
   "metadata": {},
   "source": [
    "The DataList object can accept any number of plugins in input.\n",
    "\n",
    "You can also create a list of plugins, and then create a DataList using the \"expansion\" feature of the python language ('*'), like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a42b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is equivalent to write data = DataList(xyl, ogip)\n",
    "\n",
    "my_plugins = [xyl, ogip]\n",
    "data = DataList(*my_plugins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d636e30",
   "metadata": {},
   "source": [
    "This is useful if you need to create the list of plugins at runtime, for example looping over many files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5051c0",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "\n",
    "After you have loaded your data, you need to define a model for them. A model is a collection of one or more sources. A source represents an astrophysical reality, like a star, a galaxy, a molecular cloud... There are 3 kinds of sources: PointSource, ExtendedSource and ParticleSource. The latter is used only in special situations. The models are defined using the package astromodels. Here we will only go through the basics. You can find a lot more information here: [astromodels.readthedocs.org](https://astromodels.readthedocs.org)\n",
    "\n",
    "### Point sources\n",
    "A point source is characterized by a name, a position, and a spectrum. These are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c54d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A point source with a power law spectrum\n",
    "\n",
    "source1_sp = Powerlaw()\n",
    "source1 = PointSource(\"source1\", ra=23.5, dec=-22.7, spectral_shape=source1_sp)\n",
    "\n",
    "# Another source with a log-parabolic spectrum plus a power law\n",
    "\n",
    "source2_sp = Log_parabola() + Powerlaw()\n",
    "source2 = PointSource(\"source2\", ra=30.5, dec=-27.1, spectral_shape=source2_sp)\n",
    "\n",
    "# A third source defined in terms of its Galactic latitude and longitude\n",
    "source3_sp = Cutoff_powerlaw()\n",
    "source3 = PointSource(\"source3\", l=216.1, b=-74.56, spectral_shape=source3_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0131c4a9",
   "metadata": {},
   "source": [
    "### Extended sources\n",
    "\n",
    "An extended source is characterized by its spatial shape and its spectral shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aac524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An extended source with a Gaussian shape centered on R.A., Dec = (30.5, -27.1)\n",
    "# and a sigma of 3.0 degrees\n",
    "ext1_spatial = Gaussian_on_sphere(lon0=30.5, lat0=-27.1, sigma=3.0)\n",
    "ext1_spectral = Powerlaw()\n",
    "\n",
    "ext1 = ExtendedSource(\"ext1\", ext1_spatial, ext1_spectral)\n",
    "\n",
    "# An extended source with a 3D function \n",
    "# (i.e., the function defines both the spatial and the spectral shape)\n",
    "ext2_spatial = Continuous_injection_diffusion()\n",
    "ext2 = ExtendedSource(\"ext2\", ext2_spatial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503f6fc7",
   "metadata": {},
   "source": [
    "**NOTE**: not all plugins support extended sources. For example, the XYLike plugin we used above do not, as it is meant for data without spatial resolution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de90641c",
   "metadata": {},
   "source": [
    "### Create the likelihood model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c8b1d6",
   "metadata": {},
   "source": [
    "Now that we have defined our sources, we can create a model simply as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(source1, source2, source3, ext1, ext2)\n",
    "\n",
    "# We can see a summary of the model like this:\n",
    "model.display(complete=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ed8d7",
   "metadata": {},
   "source": [
    "You can easily interact with the model. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba14857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix a parameter\n",
    "model.source1.spectrum.main.Powerlaw.K.fix = True\n",
    "# or\n",
    "model.source1.spectrum.main.Powerlaw.K.free = False\n",
    "\n",
    "# Free it again\n",
    "model.source1.spectrum.main.Powerlaw.K.free = True\n",
    "# or\n",
    "model.source1.spectrum.main.Powerlaw.K.fix = False\n",
    "\n",
    "# Change the value\n",
    "model.source1.spectrum.main.Powerlaw.K = 2.3\n",
    "# or using physical units (need to be compatible with what shown \n",
    "# in the table above)\n",
    "model.source1.spectrum.main.Powerlaw.K = 2.3 * 1 / (u.cm**2 * u.s * u.TeV)\n",
    "\n",
    "# Change the boundaries for the parameter\n",
    "model.source1.spectrum.main.Powerlaw.K.bounds = (1e-10, 1.0)\n",
    "# you can use units here as well, like:\n",
    "model.source1.spectrum.main.Powerlaw.K.bounds = (1e-5 * 1 / (u.cm**2 * u.s * u.TeV), \n",
    "                                                 10.0 * 1 / (u.cm**2 * u.s * u.TeV))\n",
    "\n",
    "# Link two parameters so that they are forced to have the same value\n",
    "model.link(model.source2.spectrum.main.composite.K_1,\n",
    "           model.source1.spectrum.main.Powerlaw.K)\n",
    "\n",
    "# Link two parameters with a law. The parameters of the law become free\n",
    "# parameters in the fit. In this case we impose a linear relationship\n",
    "# between the index of the log-parabolic spectrum and the index of the\n",
    "# powerlaw in source2: index_2 = a * alpha_1 + b. \n",
    "\n",
    "law = Line()\n",
    "model.link(model.source2.spectrum.main.composite.index_2,\n",
    "           model.source2.spectrum.main.composite.alpha_1,\n",
    "           law)\n",
    "\n",
    "# If you want to force them to be in a specific relationship,\n",
    "# say index_2 = alpha_1 + 1, just fix a and b to the corresponding values,\n",
    "# after the linking, like:\n",
    "# model.source2.spectrum.main.composite.index_2.Line.a = 1.0\n",
    "# model.source2.spectrum.main.composite.index_2.Line.a.fix = True\n",
    "# model.source2.spectrum.main.composite.index_2.Line.b = 0.0\n",
    "# model.source2.spectrum.main.composite.index_2.Line.b.fix = True\n",
    "\n",
    "# Now display() will show the links\n",
    "model.display(complete=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fbde89",
   "metadata": {},
   "source": [
    "Now, for the following steps, let's keep it simple and let's use a single point source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf667385",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Model(source1)\n",
    "\n",
    "source1_sp.K.bounds = (0.01, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dd7f55",
   "metadata": {},
   "source": [
    "A model can be saved to disk, and reloaded from disk, as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2b02f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.save(\"new_model.yml\", overwrite=True)\n",
    "\n",
    "new_model_reloaded = load_model(\"new_model.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e0c25",
   "metadata": {},
   "source": [
    "The output is in [YAML format](http://www.yaml.org/start.html), a human-readable text-based format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c12471f",
   "metadata": {},
   "source": [
    "## Perform the analysis\n",
    "\n",
    "### Maximum likelihood analysis\n",
    "\n",
    "Now that we have the data and the model, we can perform an analysis very easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa1574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataList(ogip)\n",
    "\n",
    "jl = JointLikelihood(new_model, data)\n",
    "\n",
    "best_fit_parameters, likelihood_values = jl.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f81c63",
   "metadata": {},
   "source": [
    "The output of the fit() method of the JointLikelihood object consists of two pandas DataFrame objects, which can be queried, saved to disk, reloaded and so on. Refer to the [pandas manual](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe) for details.\n",
    "\n",
    "After the fit the JointLikelihood instance will have a .results attribute which contains the results of the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a410f7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "jl.results.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8d288a",
   "metadata": {},
   "source": [
    "This object can be saved to disk in a FITS file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f2828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jl.results.write_to(\"my_results.fits\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83924256",
   "metadata": {},
   "source": [
    "The produced FITS file contains the complete definition of the model and of the results, so it can be reloaded in a separate session as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4833ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_reloaded = load_analysis_results(\"my_results.fits\")\n",
    "\n",
    "results_reloaded.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d62fb1",
   "metadata": {},
   "source": [
    "The flux of the source can be computed from the 'results' object (even in another session by reloading the FITS file), as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc378a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxes = jl.results.get_flux(100 * u.keV, 1 * u.MeV)\n",
    "\n",
    "# Same results would be obtained with\n",
    "# fluxes = results_reloaded.get_point_source_flux(100 * u.keV, 1 * u.MeV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a31a40e",
   "metadata": {},
   "source": [
    "We can change the energy range on the fly... even from the reloaded fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f8922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxes = jl.results.get_flux(100 * u.eV, 1 * u.TeV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76230635",
   "metadata": {},
   "source": [
    "We can also plot the spectrum with its error region, as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216dfee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_spectra(jl.results, ene_min=0.1, ene_max=1e6, num_ene=500, \n",
    "                          flux_unit='erg / (cm2 s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e09797",
   "metadata": {},
   "source": [
    "### Bayesian analysis\n",
    "In a very similar way, we can also perform a Bayesian analysis. As a first step, we need to define the priors for all parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae29ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# It can be set using the currently defined boundaries\n",
    "new_model.source1.spectrum.main.Powerlaw.index.set_uninformative_prior(Uniform_prior)\n",
    "\n",
    "# or uniform prior can be defined directly, like:\n",
    "new_model.source1.spectrum.main.Powerlaw.index.prior = Uniform_prior(lower_bound=-3, \n",
    "                                                                     upper_bound=0)\n",
    "\n",
    "\n",
    "# The same for the Log_uniform prior\n",
    "new_model.source1.spectrum.main.Powerlaw.K.prior = Log_uniform_prior(lower_bound=1e-3, \n",
    "                                                                     upper_bound=100)\n",
    "# or\n",
    "new_model.source1.spectrum.main.Powerlaw.K.set_uninformative_prior(Log_uniform_prior)\n",
    "\n",
    "new_model.display(complete=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9531e73",
   "metadata": {},
   "source": [
    "Then, we can perform our Bayesian analysis like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d298b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = BayesianAnalysis(new_model, data)\n",
    "bs.set_sampler('ultranest')\n",
    "bs.sampler.setup()\n",
    "# This uses the ultranest sampler\n",
    "samples = bs.sample(quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b806897",
   "metadata": {},
   "source": [
    "The BayesianAnalysis object will now have a \"results\" member which will work exactly the same as explained for the Maximum Likelihood analysis (see above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac89125",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs.results.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b91695",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxes_bs = bs.results.get_flux(100 * u.keV, 1 * u.MeV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85b0424",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_spectra(bs.results, ene_min=0.1, ene_max=1e6, num_ene=500, \n",
    "                          flux_unit='erg / (cm2 s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbad9ab",
   "metadata": {},
   "source": [
    "We can also produce easily a \"corner plot\", like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99da7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs.results.corner_plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a7cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
